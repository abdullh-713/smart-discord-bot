import discord
from discord.ext import commands
from PIL import Image
import torchvision.transforms as transforms
import torch
import torch.nn as nn
from torchvision.models import resnet50
import io
import cv2
import numpy as np
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙ„Ø§Ø­ÙŠØ§Øª Ø§Ù„Ø¨ÙˆØª
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet50 ÙˆØªØ¹Ø¯ÙŠÙ„Ù‡ Ù„ØªØµÙ†ÙŠÙ (ØµØ¹ÙˆØ¯ / Ù‡Ø¨ÙˆØ· ÙÙ‚Ø·)
model = resnet50(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 2)  # ÙØ¦ØªØ§Ù† ÙÙ‚Ø·: ØµØ¹ÙˆØ¯ / Ù‡Ø¨ÙˆØ·
model.eval()

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Ù‚Ø±Ø§Ø±Ø§Øª
labels_map = {
    0: "ğŸ“ˆ ØµØ¹ÙˆØ¯",
    1: "ğŸ“‰ Ù‡Ø¨ÙˆØ·"
}

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø´Ù…ÙˆØ¹ + Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
def extract_indicator_regions(img_pil):
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    h, w, _ = img_cv.shape

    # Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù‚Øµ: Ø­Ø³Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙˆØ±Ø©
    candles = img_cv[int(0.05*h):int(0.55*h), int(0.1*w):int(0.9*w)]
    rsi     = img_cv[int(0.85*h):int(0.95*h), int(0.1*w):int(0.9*w)]
    macd    = img_cv[int(0.75*h):int(0.85*h), int(0.1*w):int(0.9*w)]
    boll    = img_cv[int(0.05*h):int(0.55*h), int(0.1*w):int(0.9*w)]

    return [candles, rsi, macd, boll]

# ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø¬Ø²Ø¡ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ ResNet ÙˆØªØ­Ù„ÙŠÙ„Ù‡
def preprocess_region(region):
    image = Image.fromarray(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))
    return transform(image).unsqueeze(0)

# ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ù†Ø·Ù‚Ø© ÙˆØ¥Ø¹Ø·Ø§Ø¡ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
def predict_signal(regions):
    signals = []
    for region in regions:
        tensor = preprocess_region(region)
        with torch.no_grad():
            output = model(tensor)
            _, pred = torch.max(output, 1)
            signals.append(pred.item())

    # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ØªØµÙˆÙŠØª: Ø¥Ø°Ø§ Ø§Ù„Ø£ØºÙ„Ø¨ÙŠØ© ØµØ¹ÙˆØ¯ => ØµØ¹ÙˆØ¯
    final = 0 if signals.count(0) > signals.count(1) else 1
    return labels_map[final]

# Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
@bot.event
async def on_ready():
    print(f"âœ… Logged in as {bot.user}")

# Ø¹Ù†Ø¯ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±Ø©
@bot.event
async def on_message(message):
    if message.author == bot.user:
        return

    if message.attachments:
        for attachment in message.attachments:
            if any(attachment.filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg']):
                try:
                    image_bytes = await attachment.read()
                    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
                    regions = extract_indicator_regions(image)
                    signal = predict_signal(regions)
                    await message.channel.send(f"ğŸ¤– Ù‚Ø±Ø§Ø± Ø§Ù„Ø¨ÙˆØª: **{signal}**")
                except Exception as e:
                    await message.channel.send(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")

    await bot.process_commands(message)

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙˆÙƒÙ† Ù…Ù† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©
bot.run(os.getenv("TOKEN"))
