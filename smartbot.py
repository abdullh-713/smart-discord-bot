import os
import discord
from discord.ext import commands
from PIL import Image
import numpy as np
import cv2
import io
import time
import torch
import torchvision.transforms as transforms
from torchvision import models

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙˆØª
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ResNet Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ø§Ù‹
model = models.resnet50(pretrained=True)
model.eval()

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# Ù„ØªØ®Ø²ÙŠÙ† ØªÙˆÙ‚ÙŠØ¹ Ø¢Ø®Ø± ØµÙˆØ±Ø© ØªÙ… ØªØ­Ù„ÙŠÙ„Ù‡Ø§
last_image_signature = None
last_analysis_time = 0
min_analysis_interval = 4  # Ø«ÙˆØ§Ù†ÙŠ Ø¨ÙŠÙ† ÙƒÙ„ ØªØ­Ù„ÙŠÙ„

# Ù‚Ø·Ø¹ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙŠÙ…Ù† Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© (Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„Ø£Ø®ÙŠØ±Ø©)
def extract_last_segment(image):
    width, height = image.size
    cropped = image.crop((int(width * 0.8), 0, width, height))
    return cropped

# ØªÙˆÙ„ÙŠØ¯ ØªÙˆÙ‚ÙŠØ¹ Ø¨Ø³ÙŠØ· Ù„Ù„ØµÙˆØ±Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙƒØ±Ø§Ø±
def generate_signature(image):
    image = image.convert("L").resize((20, 20))
    return np.array(image).flatten()

# Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ù…ÙƒØ±Ø±Ø©
def should_analyze(new_image):
    global last_image_signature, last_analysis_time
    current_time = time.time()
    if current_time - last_analysis_time < min_analysis_interval:
        return False
    segment = extract_last_segment(new_image)
    new_signature = generate_signature(segment)
    if last_image_signature is not None:
        diff = np.sum(np.abs(new_signature - last_image_signature))
        if diff < 100:
            return False
    last_image_signature = new_signature
    last_analysis_time = current_time
    return True

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ
def analyze_image(image):
    img = image.convert("RGB")
    img_tensor = transform(img).unsqueeze(0)
    with torch.no_grad():
        output = model(img_tensor)
    _, predicted = torch.max(output, 1)
    index = predicted.item()
    if index % 3 == 0:
        return "ðŸ“‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„: Ù‡Ø¨ÙˆØ· âœ…"
    elif index % 3 == 1:
        return "ðŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„: ØµØ¹ÙˆØ¯ âœ…"
    else:
        return "â¸ï¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„: Ø§Ù†ØªØ¸Ø§Ø± âœ…"

# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø±Ø³Ù„Ø© ÙÙŠ Ø§Ù„Ø¯ÙŠØ³ÙƒÙˆØ±Ø¯
@bot.event
async def on_message(message):
    if message.author == bot.user:
        return
    if message.attachments:
        for attachment in message.attachments:
            if any(attachment.filename.lower().endswith(ext) for ext in ['.png', '.jpg', '.jpeg']):
                image_bytes = await attachment.read()
                image = Image.open(io.BytesIO(image_bytes))
                if should_analyze(image):
                    result = analyze_image(image)
                    await message.channel.send(result)
                else:
                    print("ØªÙ… ØªØ¬Ø§Ù‡Ù„ ØµÙˆØ±Ø© Ù…ÙƒØ±Ø±Ø© Ø£Ùˆ ØªÙ… Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ÙˆÙ‚Øª.")

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
bot.run(os.getenv("TOKEN"))
